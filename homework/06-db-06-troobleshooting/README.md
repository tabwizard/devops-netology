# Домашняя работа к занятию "6.6. Troubleshooting"

## Задача 1

Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).

Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её
нужно прервать.

Вы как инженер поддержки решили произвести данную операцию:

- напишите список операций, которые вы будете производить для остановки запроса пользователя
- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB  

__ОТВЕТ:__

- > напишите список операций, которые вы будете производить для остановки запроса пользователя
  - Если пользователь знает точный текст запроса, то можно попытаться установить ему максимальное время выполнения, например, 30 мсек (что гораздо меньше чем прошло) `db.location.find({ текст запроса }).maxTimeMS(30)` и запрос должен завершиться средствами СУБД.  
  - Или мы можем с помощью  
`db.currentOp({ "secs_running" : { "$gte" : 180 }})` найти операцию, длящуюся больше 180 секунд, узнать её `opid` и потом с помощью `db.killOp(opid);` убить её.
- >предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB
  - Для решения проблем с долгими запросами можно включить `db.enableFreeMonitoring()` и смотреть что происходит и потом ручками разбираться с проблемами с помощью `db.currentOp`, `.explain()` и `db.killOp`.
  - Можно написать скрипт, который через какой-то промежуток времени будет запускать поиск проблемных запросов `db.currentOp({ "secs_running" : { "$gte" : ХХ }})`, если что-то нашлось писать куда-нибудь в логу полученный вывод для отчетности и последующих разборок и потом молча убивать `db.killOp(opid);`.
  - Ещё можно попытаться попросить разработчиков использовать `cursor.maxTimeMS()` чтобы такая проблема не возникала.

## Задача 2

Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).

Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL.
Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и
увеличивается пропорционально количеству реплик сервиса.

При масштабировании сервиса до N реплик вы увидели, что:

- сначала рост отношения записанных значений к истекшим
- Redis блокирует операции записи

Как вы думаете, в чем может быть проблема?  

__ОТВЕТ:__

- >сначала рост отношения записанных значений к истекшим
  - по какой-то причине записи перестают становиться истекшими и остаются записанными (действующими) можно предположить, что на хост-машине кончились "свободные" вычислительные ядра и процессы Redis, а так же AOF/fsync/RDB блокируют друг друга. Не зря же рекомендуют чтобы под каждый инстанс Redis было выделено 2 ядра (под сам процесс и под AOF/fsync/RDB)
  
- >Redis блокирует операции записи
  - могу предположить, что так как запись производится методом `fork`, что приводит к увеличению занятой памяти, не только на размер записываемых данных, но и на вторую копию таблицы страниц занятой памяти, то закончившаяся свободная память повлечет за собой блокировку записи.  

## Задача 3

Перед выполнением задания познакомьтесь с документацией по [Common Mysql errors](https://dev.mysql.com/doc/refman/8.0/en/common-errors.html).

Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы,
пользователи начали жаловаться на ошибки вида:

```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

Как вы думаете, почему это начало происходить и как локализовать проблему?

Какие пути решения данной проблемы вы можете предложить?  

__ОТВЕТ:__
Судя по тому, что СУБД используется в гис-системе и проблемы начались с ростом количества записей возможно:

- ответ на запрос содержит большое количество записей которые СУБД не успевает передать за установленне временя `net_read_timeout`, предлагается увеличить размер этого параметра до 60 секунд;
- передаются какие-то большие BLOB данные и поэтому перестало хватать установленного максимального размера пакета `max_allowed_packet`, предлагается увеличить его сделав больше самого большого пакета, любой сгенерированной/промежуточной строки, любого параметра, значения в запросе/ответе.

## Задача 4

Перед выполнением задания ознакомтесь со статьей [Common PostgreSQL errors](https://www.percona.com/blog/2020/06/05/10-common-postgresql-errors/) из блога Percona.

Вы решили перевезти гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с
большим объемом данных лучше, чем MySQL.

После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

`postmaster invoked oom-killer`

Как вы думаете, что происходит?

Как бы вы решили данную проблему?

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---

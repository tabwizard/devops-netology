# Домашняя работа к занятию "11.03 Микросервисы: подходы"

Вы работаете в крупной компанию, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps специалисту необходимо выдвинуть предложение по организации инфраструктуры, для разработки и эксплуатации.

## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

- Облачная система;
- Система контроля версий Git;
- Репозиторий на каждый сервис;
- Запуск сборки по событию из системы контроля версий;
- Запуск сборки по кнопке с указанием параметров;
- Возможность привязать настройки к каждой сборке;
- Возможность создания шаблонов для различных конфигураций сборок;
- Возможность безопасного хранения секретных данных: пароли, ключи доступа;
- Несколько конфигураций для сборки из одного репозитория;
- Кастомные шаги при сборке;
- Собственные докер образы для сборки проектов;
- Возможность развернуть агентов сборки на собственных серверах;
- Возможность параллельного запуска нескольких сборок;
- Возможность параллельного запуска тестов;

Обоснуйте свой выбор.

**ОТВЕТ:** Для обеспечения разработки: хранения исходного кода, непрерывной интеграции и непрерывной поставки предлагаю использовать мощное, современное решение сочетающее в себе все необходимые для этого компоненты - `GitLab`

`GitLab` — это платформа управления Git-репозиториями, анализа кода, отслеживания ошибок, тестирования, деплоя, ведения каналов и вики-страниц.

`GitLab` помогает разработчикам вести непрерывный процесс развертывания для тестирования, создания и деплоя кода, следить за ходом тестов, повышать контроль над качеством, фокусирования на построении продукта вместо настройки инструментов.

`GitLab` может работать на собственном сервере или в облаке. Для обоих случаев существуют полностью бесплатная версия и платные тарифы, стоимость которых зависит от функционала.

Ключевые возможности `GitLab`:

- Организация публичных и приватных репозиториев.
- Управление правами, группами.
- Импорт проектов, в том числе с GitHub.
- Вики.
- API.
- Доска идей и задач.
- Лейблы, вехи, шаблоны, поиск.
- Комментирование, объединение.
- Интеграция с Jenkins CI.
- Отслеживание изменений и прогресса.
- Отслеживание времени.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

- Сбор логов в центральное хранилище со всех хостов обслуживающих систему;
- Минимальные требования к приложениям, сбор логов из stdout;
- Гарантированная доставка логов до центрального хранилища;
- Обеспечение поиска и фильтрации по записям логов;
- Обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- Возможность дать ссылку на сохраненный поиск по записям логов;

Обоснуйте свой выбор.

**ОТВЕТ:** Для обеспечения сбора и анализа логов предлагаю использовать проверенный временем стек `ELK` + `Filebeat`

`ELK` — это аббревиатура из названий трех продуктов: Elasticsearch, Logstash и Kibana. Это три продукта с открытым кодом, которые в некоторый момент времени стали принадлежать одной компании и развиваться в одном направлении. Итак, для чего же они нужны.

`Logstash` — это инструмент получения, преобразования и сохранения данных в общем хранилище. Его первой задачей является прием данных в каком-либо виде: из файла, базы данных, логов или информационных каналов. Далее полученная информация может модифицироваться с помощью фильтров, например, единая строка может быть разбита на поля, могут добавляться или изменяться данные, несколько строк могут агрегироваться и т.п. Обработанная информация посылается в системы — потребители этой информации. Говоря о связке ELK, потребителем информации будет Elasticsearch, однако возможны другие варианты, например системы мониторинга и управления (Nagios, Jira и др.), системы хранения информации (Google Cloud Storage, syslog и др.), файлы на диске. Возможен даже запуск команды при получении особого набора данных.

`Elasticsearch` — это собственно механизм индексирования и хранения полученной информации, а также полнотекстового поиска по ней. Он основан на библиотеке Apache Lucene и, по сути, является NoSQL database решением. Главная задача этого инструмента — организация быстрого и гибкого поиска по полученным данным. Для ее решения имеется возможность выбора анализаторов текста, функционал «нечеткого поиска», поддерживается поиск по информации на восточных языках (корейский, китайский, японский). Работа с информацией происходит с помощью REST API, который позволяет добавлять, просматривать, модифицировать и удалять данные. Однако в случае использования ELK этот вопрос остается внутри «черной коробочки», поскольку у нас есть уже выше описанный Logstash и Kibana.

`Kibana` — это user friendly интерфейс, для Elasticsearch, который имеет большое количество возможностей по поиску данных в дебрях индексов Elasticsearch и отображению этих данных в удобочитаемых видах  таблиц, графиков и диаграмм.

`Filebeat` транслирует на сервер информацию из динамических обновляемых журналов системы и файлов, содержащих текстовую информацию. Для аналогичных действий с журналами Windows-систем используется Winlogbeat. По сравнению с Logstash FileBeat более легкий.

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:

- Сбор метрик со всех хостов, обслуживающих систему;
- Сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- Сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- Сбор метрик, специфичных для каждого сервиса;
- Пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- Пользовательский интерфейс с возможность настраивать различные панели для отслеживания состояния системы;

Обоснуйте свой выбор.

**ОТВЕТ:** Для обеспечения мониторинга хостов и сервисов предлагаю использовать решение на основе `Prometheus`+`Grafana`+`Node_exporter`

`Prometheus` - центральный сервер, предназначенный для сбора и хранения данных. Данные постоянно изменяются во времени (например, уровень заполненности диска, трафик через сетевой интерфейс, время отклика сайта). Элементы данных называются метриками. Сервер Prometheus с заданной периодичностью считывает метрики и помещает полученные данные в Time Series DB. Time Series DB - это разновидность баз данных, предназначенная для хранения временных рядов (значений с привязкой ко времени). Кроме того, Prometheus предоставляет интерфейс для выполнения запросов и визуализации полученных данных. Язык запросов Prometheus называется PromQL. Prometheus работает по модели Pull, то есть он сам опрашивает endpoints с целью получения данных.

`Exporters` - процессы, обеспечивающие сбор и их передачу серверу Prometheus. Существует много разных exporters, например:  

- `Node_exporter` - сбор системных метрик (процессор, память, и т.д.).
- `Mysqld_exporter` - сбор метрик работы сервера MySQL.
- `Postgres_exporter` - сбор метрик работы сервера PostgreSQL.
После запуска exporter начинает сбор соответствующих метрик и ожидает запросов от сервера Prometheus по заданному порту. Данных передаются в формате http.

`Grafana` - удобный frontend для визуализации накопленных данных, может использоваться для работы с данными сервера Prometheus, предоставляет различные преднастроенные Dashboard для отображения данных.  

Помимо функций сбора, анализа и визуализации данных, Prometheus и Grafana поддерживают настраиваемые оповещения. В Grafana этот механизм является встроенным, в Prometheus он реализуется отдельным компонентом (Alert_manager).

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче пишут логи в stdout.

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов обеспечивающих работу API.

### Результат выполнения

docker compose файл запустив который можно перейти по адресу <http://localhost:8081> по которому доступна Kibana.
Логин в Kibana должен быть admin пароль qwerty123456

## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы используемые в задаче предоставляют набор метрик в формате prometheus:

- Сервис security по адресу /metrics
- Сервис uploader по адресу /metrics
- Сервис storage (minio) по адресу /minio/v2/metrics/cluster

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов обеспечивающих работу API.
Построить в Graphana dashboard показывающий распределение запросов по сервисам.

### Результат выполнения

docker compose файл запустив который можно перейти по адресу <http://localhost:8081> по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin пароль qwerty123456

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
